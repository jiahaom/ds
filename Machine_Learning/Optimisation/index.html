<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Here is the page description. This is an example Quartz site that details installation, setup, customization, and troubleshooting for Quartz itself."><title>Optimisation</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=../../icon.png><link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700&family=Source+Sans+Pro:wght@400;700&family=Fira+Code:wght@400;700&display=swap" rel=stylesheet><style>:root{--light:#faf8f8;--dark:#141021;--secondary:#284b63;--tertiary:#84a59d;--visited:#afbfc9;--primary:#f28482;--gray:#4e4e4e;--lightgray:#f0f0f0;--outlinegray:#dadada}[saved-theme=dark]{--light:#1e1e21 !important;--dark:#fbfffe !important;--secondary:#5b778a !important;--visited:#4a575e !important;--tertiary:#84a59d !important;--primary:#f58382 !important;--gray:#d4d4d4 !important;--lightgray:#292633 !important;--outlinegray:#343434 !important}</style><style>:root{--lt-colours-light:var(--light) !important;--lt-colours-lightgray:var(--lightgray) !important;--lt-colours-dark:var(--secondary) !important;--lt-colours-secondary:var(--tertiary) !important;--lt-colours-gray:var(--outlinegray) !important}code.has-jax{-webkit-font-smoothing:antialiased;background:inherit!important;border:none!important;font-size:100%}h1,h2,h3,h4,ol,ul,thead{font-family:Inter;color:var(--dark);font-weight:revert;margin:revert;padding:revert}p,ul,text{font-family:source sans pro,sans-serif;color:var(--gray);fill:var(--gray);font-weight:revert;margin:revert;padding:revert}a{font-family:Inter;font-weight:700;font-size:1em;text-decoration:none;transition:all .2s ease;color:var(--secondary)}a:hover{color:var(--tertiary)!important}#TableOfContents>ol{counter-reset:section;margin-left:0;padding-left:1.5em}#TableOfContents>ol>li{counter-increment:section}#TableOfContents>ol>li>ol{counter-reset:subsection}#TableOfContents>ol>li>ol>li{counter-increment:subsection}#TableOfContents>ol>li>ol>li::marker{content:counter(section)"." counter(subsection)"  "}#TableOfContents>ol>li::marker{content:counter(section)"  "}#TableOfContents>ol>li::marker,#TableOfContents>ol>li>ol>li::marker{font-family:Source Sans Pro;font-weight:700}footer{margin-top:4em;text-align:center}table{width:100%}img{width:100%;border-radius:3px;margin:1em 0}p>img+em{display:block;transform:translateY(-1em)}sup{line-height:0}p,tbody,li{font-family:Source Sans Pro;color:var(--gray);line-height:1.5em}h2{opacity:.85}h3{opacity:.75}blockquote{margin-left:0;border-left:3px solid var(--secondary);padding-left:1em;transition:border-color .2s ease}blockquote:hover{border-color:var(--tertiary)}table{padding:1.5em}td,th{padding:.1em .5em}.footnotes p{margin:.5em 0}article a{font-family:Source Sans Pro;font-weight:600;text-decoration:underline;text-decoration-color:var(--tertiary);text-decoration-thickness:.15em}sup>a{text-decoration:none;padding:0 .1em 0 .2em}pre{font-family:fira code;padding:.75em;border-radius:3px;overflow-x:scroll}code{font-family:fira code;font-size:.85em;padding:.15em .3em;border-radius:5px;background:var(--lightgray)}html{scroll-behavior:smooth}body{margin:0;height:100vh;width:100vw;overflow-x:hidden;background-color:var(--light)}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}footer{margin-top:4em}footer>a{font-size:1em;color:var(--secondary);padding:0 .5em 3em}hr{width:25%;margin:4em auto;height:2px;border-radius:1px;border-width:0;color:var(--dark);background-color:var(--dark)}a[href^="/"]{text-decoration:none;background-color:#afbfc922;padding:0 .2em;border-radius:3px}.singlePage{margin:4em 30vw}@media all and (max-width:1200px){.singlePage{margin:25px 5vw}}.page-end{display:flex;flex-direction:row}@media all and (max-width:780px){.page-end{flex-direction:column}}.page-end>*{flex:1 0}.page-end>.backlinks-container>ul{list-style:none;padding-left:0;margin-right:2em}.page-end>.backlinks-container>ul>li{margin:.5em 0;padding:.25em 1em;border:var(--outlinegray)1px solid;border-radius:5px}.page-end #graph-container{border:var(--outlinegray)1px solid;border-radius:5px}.centered{margin-top:30vh}header{display:flex;flex-direction:row;align-items:center}header>h1{font-size:2em}@media all and (max-width:600px){header>nav{display:none}}header>.spacer{flex:auto}header>svg{cursor:pointer;width:18px;min-width:18px;margin:0 1em}header>svg:hover .search-path{stroke:var(--tertiary)}header>svg .search-path{stroke:var(--gray);stroke-width:2px;transition:stroke .5s ease}#search-container{position:fixed;z-index:9999;left:0;top:0;width:100vw;height:100%;overflow:scroll;display:none;backdrop-filter:blur(4px);-webkit-backdrop-filter:blur(4px)}#search-container>div{width:50%;margin-top:15vh;margin-left:auto;margin-right:auto}@media all and (max-width:1200px){#search-container>div{width:90%}}#search-container>div>*{width:100%;border-radius:4px;background:var(--light);box-shadow:0 14px 50px rgba(27,33,48,.12),0 10px 30px rgba(27,33,48,.16);margin-bottom:2em}#search-container>div>input{box-sizing:border-box;padding:.5em 1em;font-family:Inter,sans-serif;color:var(--dark);font-size:1.1em;border:1px solid var(--outlinegray)}#search-container>div>input:focus{outline:none}#search-container>div>#results-container>.result-card{padding:1em;cursor:pointer;transition:background .2s ease;border:1px solid var(--outlinegray);border-bottom:none;width:100%;font-family:inherit;font-size:100%;line-height:1.15;margin:0;overflow:visible;text-transform:none;text-align:left;background:var(--light);outline:none}#search-container>div>#results-container>.result-card:hover,#search-container>div>#results-container>.result-card:focus{background:rgba(180,180,180,.15)}#search-container>div>#results-container>.result-card:first-of-type{border-top-left-radius:5px;border-top-right-radius:5px}#search-container>div>#results-container>.result-card:last-of-type{border-bottom-left-radius:5px;border-bottom-right-radius:5px;border-bottom:1px solid var(--outlinegray)}#search-container>div>#results-container>.result-card>h3,#search-container>div>#results-container>.result-card>p{margin:0}#search-container>div>#results-container>.result-card .search-highlight{background-color:#afbfc966;padding:.05em .2em;border-radius:3px}</style><style>.darkmode{float:right;padding:1em;min-width:30px;position:relative}@media all and (max-width:450px){.darkmode{padding:1em}}.darkmode>.toggle{display:none;box-sizing:border-box}.darkmode svg{opacity:0;position:absolute;width:20px;height:20px;top:calc(50% - 10px);margin:0 7px;fill:var(--gray);transition:opacity .1s ease}.toggle:checked~label>#dayIcon{opacity:0}.toggle:checked~label>#nightIcon{opacity:1}.toggle:not(:checked)~label>#dayIcon{opacity:1}.toggle:not(:checked)~label>#nightIcon{opacity:0}</style><style>.chroma{color:#f8f8f2;background-color:#282a36}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0;width:auto;overflow:auto;display:block}.chroma .hl{display:block;width:100%;background-color:#ffc}.chroma .lnt{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .k{color:#ff79c6}.chroma .kc{color:#ff79c6}.chroma .kd{color:#8be9fd;font-style:italic}.chroma .kn{color:#ff79c6}.chroma .kp{color:#ff79c6}.chroma .kr{color:#ff79c6}.chroma .kt{color:#8be9fd}.chroma .na{color:#50fa7b}.chroma .nb{color:#8be9fd;font-style:italic}.chroma .nc{color:#50fa7b}.chroma .nf{color:#50fa7b}.chroma .nl{color:#8be9fd;font-style:italic}.chroma .nt{color:#ff79c6}.chroma .nv{color:#8be9fd;font-style:italic}.chroma .vc{color:#8be9fd;font-style:italic}.chroma .vg{color:#8be9fd;font-style:italic}.chroma .vi{color:#8be9fd;font-style:italic}.chroma .s{color:#f1fa8c}.chroma .sa{color:#f1fa8c}.chroma .sb{color:#f1fa8c}.chroma .sc{color:#f1fa8c}.chroma .dl{color:#f1fa8c}.chroma .sd{color:#f1fa8c}.chroma .s2{color:#f1fa8c}.chroma .se{color:#f1fa8c}.chroma .sh{color:#f1fa8c}.chroma .si{color:#f1fa8c}.chroma .sx{color:#f1fa8c}.chroma .sr{color:#f1fa8c}.chroma .s1{color:#f1fa8c}.chroma .ss{color:#f1fa8c}.chroma .m{color:#bd93f9}.chroma .mb{color:#bd93f9}.chroma .mf{color:#bd93f9}.chroma .mh{color:#bd93f9}.chroma .mi{color:#bd93f9}.chroma .il{color:#bd93f9}.chroma .mo{color:#bd93f9}.chroma .o{color:#ff79c6}.chroma .ow{color:#ff79c6}.chroma .c{color:#6272a4}.chroma .ch{color:#6272a4}.chroma .cm{color:#6272a4}.chroma .c1{color:#6272a4}.chroma .cs{color:#6272a4}.chroma .cp{color:#ff79c6}.chroma .cpf{color:#ff79c6}.chroma .gd{color:#8b080b}.chroma .ge{text-decoration:underline}.chroma .gh{font-weight:700}.chroma .gi{font-weight:700}.chroma .go{color:#44475a}.chroma .gu{font-weight:700}.chroma .gl{text-decoration:underline}.lntd:first-of-type>.chroma{padding-right:0}.chroma code{font-family:fira code!important;font-size:.85em;line-height:1em;background:0 0;padding:0}.chroma{border-radius:3px;margin:0}</style><script>const userPref=window.matchMedia('(prefers-color-scheme: light)').matches?'light':'dark',currentTheme=localStorage.getItem('theme')??userPref;currentTheme&&document.documentElement.setAttribute('saved-theme',currentTheme);const switchTheme=a=>{a.target.checked?(document.documentElement.setAttribute('saved-theme','dark'),localStorage.setItem('theme','dark')):(document.documentElement.setAttribute('saved-theme','light'),localStorage.setItem('theme','light'))};window.addEventListener('DOMContentLoaded',()=>{const a=document.querySelector('#darkmode-toggle');a.addEventListener('change',switchTheme,!1),currentTheme==='dark'&&(a.checked=!0)})</script><script>MathJax={tex:{inlineMath:[['$','$'],['\\(','\\)']],displayMath:[['$$','$$'],['\\[','\\]']],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:['script','noscript','style','textarea','pre']}},window.addEventListener('load',a=>{document.querySelectorAll("mjx-container").forEach(function(a){a.parentElement.classList+='has-jax'})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><script async src="https://www.googletagmanager.com/gtag/js?id=G-LR9GM494F8"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-LR9GM494F8',{anonymize_ip:!1})}</script><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/gh/nextapps-de/flexsearch@0.7.2/dist/flexsearch.bundle.js></script><script>const removeMarkdown=(c,b={listUnicodeChar:!1,stripListLeaders:!0,gfm:!0,useImgAltText:!1,preserveLinks:!1})=>{let a=c||"";a=a.replace(/^(-\s*?|\*\s*?|_\s*?){3,}\s*$/gm,"");try{b.stripListLeaders&&(b.listUnicodeChar?a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,b.listUnicodeChar+" $1"):a=a.replace(/^([\s\t]*)([\*\-\+]|\d+\.)\s+/gm,"$1")),b.gfm&&(a=a.replace(/\n={2,}/g,"\n").replace(/~{3}.*\n/g,"").replace(/~~/g,"").replace(/`{3}.*\n/g,"")),b.preserveLinks&&(a=a.replace(/\[(.*?)\][\[\(](.*?)[\]\)]/g,"$1 ($2)")),a=a.replace(/<[^>]*>/g,"").replace(/^[=\-]{2,}\s*$/g,"").replace(/\[\^.+?\](\: .*?$)?/g,"").replace(/\s{0,2}\[.*?\]: .*?$/g,"").replace(/\!\[(.*?)\][\[\(].*?[\]\)]/g,b.useImgAltText?"$1":"").replace(/\[(.*?)\][\[\(].*?[\]\)]/g,"$1").replace(/^\s{0,3}>\s?/g,"").replace(/(^|\n)\s{0,3}>\s?/g,"\n\n").replace(/^\s{1,2}\[(.*?)\]: (\S+)( ".*?")?\s*$/g,"").replace(/^(\n)?\s{0,}#{1,6}\s+| {0,}(\n)?\s{0,}#{0,} {0,}(\n)?\s{0,}$/gm,"$1$2$3").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/([\*_]{1,3})(\S.*?\S{0,1})\1/g,"$2").replace(/(`{3,})(.*?)\1/gm,"$2").replace(/`(.+?)`/g,"$1").replace(/\n{2,}/g,"\n\n")}catch(a){return console.error(a),c}return a}</script><script>const contentIndex=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,worker:!0,document:{index:[{field:"content",tokenize:"strict",context:{resolution:5,depth:3,bidirectional:!0},suggest:!0},{field:"title",tokenize:"forward"}]}}),scrapedContent={"/":{content:"Host your second brain and [digital garden](https://jiahaom.github.io/ds/) for free. Quartz features\n1. Extremely fast full-text search by pressing `/`\n2. Beautiful, out-of-the-box website creation and deployment\n3. Display for backlinks of each note\n4. A customizable graph view\n5. Endlessly powerful page and theme customization\n\n## Get Started\n\u003e 📚[Machine_Learning](Machine_Learning/Structure/Machine_Learning.md)\n\n\u003e 📚[Supervised_Learning](Machine_Learning/Structure/Supervised_Learning.md)\n\u003e 📚[Classification](Machine_Learning/Structure/Classification.md)\n\u003e 📚[Regression](Machine_Learning/Structure/Regression.md)\n\n\u003e 📚[Unsupervised_Learning](Machine_Learning/Structure/Unsupervised_Learning.md)",title:"Machine Learning"},"/Machine_Learning/Classification":{content:"\u003e Know your metrics.\n\n- use datasets to *obtain/estimate* the (#^68e85f|Posterior Probabilities.md) instead of *using*.\n***\n## Type\n- [Linear_Classifier](Linear_Classifier.md): the simplest boundary\n- [Logistic Classifier](Logistic_Model.md): Approximated [Posterior Probabilities](The_Bayes_Classifier.md)\n- K-Nearest.md: Approximated [Posterior Probabilities](The_Bayes_Classifier.md)\n- (The_Bayes_Classifier.md): True [Posterior Probabilities](The_Bayes_Classifier.md)\n***\n## Evaluation\n[Classification_Quality_Metric](Classification_Quality_Metric.md)\n\n***\n- Shape of boundaries: Logistic regression and LDA build linear boundaries, QDA quadratic boundaries. kNN does not impose any particular shape.\n- Stability: For a small number of samples, logistic regression can be very unstable, whereas LDA approaches produce stable solutions. \n- Outliers: Logistic regression is robust against samples which lie very far from the boundary, LDA and QDA can be affected. \n- Multi-class: Multi-class problems can be implemented easily in dicriminant analysis. \n- Prior knowledge: Can be easily incorporated following Bayesian approaches",title:"Classification"},"/Machine_Learning/Classification_Quality_Metric":{content:"## Accuracy\n[[content/Machine_Learning/Regression_Quality_Metric#^e51d1f]]\n- [[content/Machine_Learning/KNN]] and [[content/Machine_Learning/Logistic_Model#^bbc977|Logistic Regression]] don't have!\n***\n## Error Rate\n(content/Machine_Learning/Regression_Quality_Metric#^9d4269)\n- [[content/Machine_Learning/KNN]] and [[content/Machine_Learning/Logistic_Model#^bbc977|Logistic Regression]] don't have!\n***\n## [[content/Machine_Learning/The_Bayes_Classifier#^a80775|A Bayesian Extension]]\n\u003e if 1 patient in 1000 people, we say all people are healthy, the accuracy is 99.9%.\n\n## Confusion Matrix\n- to see how classifier treat each class individually\n### Counting\n- ![[Screenshot 2021-11-06 at 15.10.46.png]]\n - 3 red samples are misclassified as blue\n### Rate\n-  when working with imbalanced datasets, counts might be misleading\n- ![[Screenshot 2021-11-06 at 15.13.09.png]]\n### Detection problems\n![[Screenshot 2021-11-06 at 15.22.37.png]]\n- $Accuracy = \\frac {TP+TN}{N(examples)}$\n- $Error = \\frac {FP+FN}{N(examples)} = 1 - Accuracy$\n#### Quality Metrics\n- Sensitivity / TPR / Recall\n	- $\\frac {TP}{TP+FN}$\n- Specificity / TNR\n	 - $\\frac {TN}{(TN+FP)}$\n - Precision / Positive Predictive Value\n	 - $\\frac {TP}{(TP+FP)}$\n\n### Optimization\n\u003e it's difficult to improve 1+ quality metrics at the same time ==\u003e consider pairs of them\n\n1. Sensitivity \u0026 Specificity\n- The ROC Plane\n![[Screenshot 2021-11-06 at 20.52.03.png]]\n	- top left corner is the best: $Sensitivity = 	Specificity = 1$\n	- can't rank classifiers based on them, but can filter classifiers.\n-  The AUC\n	-  area under the curve: a measure of goodness for a classifier that can be calibrated\n	-  ![[Screenshot 2021-11-07 at 21.40.20.png]]\n2. Precision \u0026 Recall\n- $F1 = 2 * \\frac {Precision*Recall}{Precision+Recall}$",title:"Classification_Quality_Metric"},"/Machine_Learning/Equivalent_numerical_representation":{content:"\u003e - different units: miles vs km\n\u003e - incommensurable: weight vs height\n\u003e - different dynamic ranges: cm vs km \n- outlier sensitive: an outlier 10 times larger than the 2nd will squeeze min-max to [0, 0.1]\n- quality guarantee on pipeline instead of these models.\n\n## Min-max normalization\n\u003e - $z = \\frac {x - min(x)}{max(x) - min(x)}$\n\u003e -  0 \u003c= z \u003c= 1\n\u003e - min(x) and max(x) are used during test and deployment\n## Standardization\n\u003e - $z = \\frac {x - \\mu}{\\sigma}$\n\u003e - mean = 0, unit standard deviation.",title:"Equivalent_numerical_representation"},"/Machine_Learning/Introduction":{content:"# Machine Learning\n- tools for modeling and understanding [[content/Machine_Learning/Introduction#^a091d7|data]] --\u003e [[content/Machine_Learning/Introduction#^d8965c|knowledge]]\n\n## Data\n- an observation or measurement or item ^a091d7\n- neutral and raw: doesn't show anything\n\n	### Attributes/ Identify\n	- Animal (ID): Wild mouse, Rabbit ...\n	- Body mass (g): 22, 4000 ...\n	- HR (bpm): 480, 250 ...\n\n## Science\n- [[content/Machine_Learning/Introduction#^240154|evaluating]] our knowledge \u003e\u003e\u003e sophisticated instrumentation\n\n	### evaluation\n	- data with accepted knowledge  ^240154\n\n\n## Knowledge\n- Proposition: T/F (statement, law)\n- Narrative: (business)\n- **Model: y=10x+3 (Math or Computer)** ^d8965c\n\n## AI\n1. act or thing rationally\n1. might use ML algorithms\n1. or use statistics or computation   ^482c57",title:"Introduction"},"/Machine_Learning/KNN":{content:"\u003e Non-parametric, instance-based approaches\n\n- doesn't have accuracy and error rate!\n\n## Nearest Neighbours\n1.  compare the whole nearest sample\n2.  assigned the label of the closest (most similar) training sample\n\n\n## K Nearest Neighbours\n- can be easily implemented in multi-class\n1.  compare the K nearest sample\n2.  assigned the label of the closest (most similar) training sample",title:"KNN"},"/Machine_Learning/Linear_Classifier":{content:"\u003e use straight lines/ planes/ hyperplanes\n\n# Boundaries\n- linear equation: $w^Tx=0$\n	- extended vector / predictors: $x=[1, x_1,x_2,...]^T$\n	- coefficients vector: $w=[w_0, w_1,w_2...]$\n	- e.g. 2D\n		- $x_2 = -\\frac{w_1}{w_2}x_1-\\frac{w_0}{w_2}$\n\n\n# Definition\n- $w^Tx\u003e0$: one side of the boundary\n- $w^Tx\u003c0$: other side of the boundary",title:"Linear_Classifier"},"/Machine_Learning/Linear_Regression":{content:"### The best linear model for training data: \n- [[content/Machine_Learning/Regression_Quality_Metric#^d91d7e|The least squares]]\n## Simple Linear Regression\n- $f(x) = w_0+w_1x$\n\n- $\\hat y =  f(x_i)= w^TX = w_0+w_1x_i$ ^b14eb7\n	- one predictor: x\n		- $X=[1,x_i]^T$\n	- one label: y\n	- use a dataset to tune two parameters to achieve the highest quality\n		- $w = [w_0, w_1]$\n		- $w_0: intercept$\n		- $w_1: slope$\n***\n\n## Multiple Linear Regression\n- $\\hat y = f(x_i) = w^Tx_i = w0+w_1x_{i,1} +...+w_Kx_{i,K}$\n	- $w=[w_o,w_1,...,w_k]$\n	- predictors:\n		- $x_i=[1,x_{i,1},x_{i,2}, ...,x_{i,K}]^T$\n		- k-th predictor of the i-th sample\n- e.g. build a linear model that maps age and height to salary:  ![[Screenshot 2021-11-15 at 11.47.06.png]]\n-	$\n\\begin{equation*}\nX = \n\\begin{bmatrix}\n1 \u0026 18 \u0026 175 \\\\\n1 \u0026 37 \u0026 180 \\\\\n1 \u0026 66 \u0026 158 \\\\\n1 \u0026 25 \u0026 168\n\\end{bmatrix}\n\\end{equation*}$, $\n\\begin{equation*}\ny = \n\\begin{bmatrix}\n12000 \\\\\n68000 \\\\\n80000 \\\\\n45000\n\\end{bmatrix}\n\\end{equation*}$\n\n***\n## Simple Polynomial Regression\n- $f(x_i) = w^TX=w_0+w_1x_i+w_2x_i^2+w_3xi^3=$\n	- $X = φ_i = [1, x_i, x_i^2, x_i^3]^T$\n	- $w^TX = w^Tφ_i$",title:"Linear_Regression"},"/Machine_Learning/Logistic_Model":{content:"## Classifier\n\n^d37bff\n\n-  $p(distance)=\\frac{e^d}{1+e^d} = \\frac{1}{1+e^{−d}}$\n- ![](Screenshot%202021-11-16%20at%2021.30.48.png)\n	- $p(0) = 0.5$\n	- $As\\ d → ∞,\\ p(d) → 1$\n	- $As\\ d → −∞,\\ p(d) → 0$\n\n- if we set the distance between boundary and sample: $d = w^Tx_i$\n	\u003e - d: label ![](Screenshot%202021-11-16%20at%2022.36.17.png)\n	- logistic function: $p(d) = \\frac {e^{w^Tx_i}}{1+e^{w^Tx_i}}$	\n\n\n## Regression ^bbc977\n- $L= \\prod_{y=red} (1 − p(x_i)) \\prod_{y=blue} p(x_i) = 0$\n### [[content/Machine_Learning/Regression_Quality_Metric]]\n- doesn't use accuracy and error rate!\n- likelihood function: $l= \\sum_{y=red} log[(1 − p(x_i)]+\\sum_{y=blue} log[p(x_i)] = 0$\n- to tune/ find maximizes L or l: [[content/Machine_Learning/Optimisation#^e433dc|Gradient Descent]]\n\n-e.g. \n- $p(0) = 0.5, p(1) ≈ 0.73, p(2) ≈ 0.88, p(−1) ≈ 0.27, p(−2) ≈ 0.12$![[Screenshot 2021-11-16 at 22.54.45.png]]\n	-  $d(triangle) = 2, d(square)=-2$\n	- $p(triangle) ≈ 0.88, 1 − p(square) ≈ 0.88$ \n	- $L = p(triangle) (1 − p(square)) ≈ 0.77$",title:"Logistic_Model"},"/Machine_Learning/Methodology":{content:"# The Value of Knowledge\n![[985DCBB1-0DD1-4752-9504-81CCE2A02E6A.jpeg]]\n\n# The Truth\n- [[Sampling#^41ffae|Dataset]] != [[Sampling#^d1148e|Population]]\n- no [[Sampling#^d1148e|Population]] in the ML\n	- no True Performance\n	- no absolute \n	- no best\n	- random: different datasets/ performance ^ccf020\n\n# 1. [[content/Machine_Learning/Training]]\n- fit a model to dataset\n# 2. [[content/Machine_Learning/Optimisation]]\n# 3. [[content/Machine_Learning/Validation]]\n- find the best mode\n# 4. [[content/Machine_Learning/Testing]]\n- verify the model\n\n\n***\n\n\u003e Don't let appearances fool you!\n\u003e - kg vs cm\n\u003e - y = 3 + 100Xa + 20Xb\n\u003e - linearly separable\n\n\n# Pipeline\n![[Screenshot 2021-11-02 at 19.24.48.png]]\n- to avoid overfitting, we need more than original data as training data.\n	- ![[Screenshot 2021-11-02 at 19.30.11.png]]\n	- if we have a pic contains 3 x A x B values (3: RGB, A x B: number of pixels), we need more than 3 x A x B pics. (too many)\n1. Data\n- [[content/Machine_Learning/Equivalent_numerical_representation]]\n2.  [[content/Machine_Learning/Transform]]\n3.  Models\n- several models running in parallel.\n- must be trained using data.\n4. [[content/Machine_Learning/Validation]]\n5. Output",title:"Methodology"},"/Machine_Learning/Neural_Network":{content:"- loosely mimmic neurons\n- a universal machine\n	- neuroscience\n	- mathematics\n\n## Architectures: \n- a family of models![[Screenshot 2021-11-17 at 10.28.27.png]]\n	- input: predictors\n	- output: label\n	- weights: parameters can be tuned/ trained",title:"Neural_Network"},"/Machine_Learning/Optimisation":{content:"\u003e find the best model if we have:\n\u003e - a collection of candidate models\n\u003e - quality metric \n\u003e - ideal description of the target population\n\n## Gradient Descent ^e433dc\n\n- update iteratively / parameter tuning\n- $w_{new} = w_{old}-\\epsilon ∇E(w_{old})$ \n	- $w: model$\n	- $\\epsilon: learning\\ rate/step\\ size$\n	- $∇E(w_{old}): slope$\n		- large: overshoot\n		- small: slow\n-  initial model $w$ is crucial\n	- usually chosen randomly\n- stopping strategy \n	- Gradient Descent will not reach the optimal model\n		- Number of iterations.\n		- Processing time. \n		- Error value. \n		- Relative change of the error value.\n\n### [[content/Machine_Learning/Regression_Quality_Metric#^d91d7e|MMSE: the best/lowest MSE for training data]] ^bab8a8\n\n- [[content/Machine_Learning/Linear_Regression#^b14eb7|Linear Model]]:\n	- $\\hat y = Xw$\n- [[content/Machine_Learning/Regression_Quality_Metric#^a03fa6|E_MSE]]:\n		- $E_{MSE}(w) = \\frac{1}{N}(y-\\hat y)^T(y-\\hat y)$\n		= $E_{MSE}(w) =\\frac{1}{N}(y-Xw)^T(y-Xw)$\n	- the resulting gradient of the MSE is:\n		- $assume:\\bigtriangledown E_{MSE}(w) = \\frac{-2}{N}X^T(y-Xw) = 0$\n			-  $w =(X^TX)^{-1}X^Ty$\n### [[content/Machine_Learning/Training#^10ee42|Training]]\n- ![[Screenshot 2021-11-16 at 09.36.33.png]]\n#### Data Size\n- Batch gradient descent: whole training dataset. \n- Stochastic gradient descent: randomly, one sample. \n- Mini-batch gradient descent: a small subset from the training dataset.\n\n### Optimisation\n- Momentum\n- RMSProp\n- Adam",title:"Optimisation"},"/Machine_Learning/Regression_Quality_Metric":{content:"- think it before build it\n***\n- embrace the error\n	- no precise input data \n	- no perfect solution\n	- therefore, represent this discrepancy as:\n		- $y = \\hat{y}+e  = f(x)+e$\n- find association between attributes instead of causation\n- build relationship instead of causal models\n\n# Error ^9d4269\n\n$E = \\frac {N(incorrect\\ samples)}{N(samples)}$\n***\n## Estimate mean squared error/ MSE ^a03fa6\n\n\u003e ![[Pasted image 20211006162907.png]] \n- find the minimum MSE:\n	- ![[Pasted image 20211006163329.png]]\n\n### The least squares ^d91d7e\n\n[[content/Machine_Learning/Optimisation#^bab8a8|MMSE: the best model for training data]]\n- might not be the best model during deployment\n- $w =(X^TX)^{-1}X^Ty$\n	-	$X: design\\ matrix$\n	-	$y: label\\ vector$\n\n\n\n***\n#### Root mean squared error/ RMSE\n-  ![[Pasted image 20211006202945.png]]\n- measures the sample standard deviation of the prediction error.\n\n#### Mean absolute error/ MAE\n- ![[Pasted image 20211006203032.png]]\n- measures the average of the absolute prediction error.\n\n#### R-squared/ R\n- ![[Pasted image 20211006203136.png]]\n-  measures the proportion of the variance in the response that is predictable from the predictors.\n***\n# Flexibility\n- the ability to capture the complexity of the underlying pattern\n- related to the number of parameters, interpretability and accuracy (trade-off)	\n\n## Interpretability\n- the ability to describe what's going on / understand how a predictor is mapped to a label\n - more Inflexible, simpler and easier to interpret.\n## Accuracy ^e51d1f\n- more flexible, less error\n- $A = \\frac {N(correct\\ samples)}{N(samples)}$\n# Generalisation\n- the ability to make good predictions / successful deployment.\n	- assessed by comparing training and deployment performance:![[Pasted image 20211006204358.png]]\n	- training [[#^a03fa6|MSE]] \u0026 deployment [[#^a03fa6|MSE]]\n	- overfitting \u0026 underfitting \u0026 just right",title:"Regression_Quality_Metric"},"/Machine_Learning/Structure/Machine_Learning":{content:"# Taxonomy \n![[F1ECE30F-8DD2-464A-8AB2-DA25F4025743.jpeg]]\n![[734CF636-E861-4899-BFCA-DBFF70E0776D.jpeg]]\n- [[content/Machine_Learning/Structure/Supervised_Learning]]\n- [[content/Machine_Learning/Structure/Unsupervised_Learning]]\n\n\n# [[content/Machine_Learning/Methodology]]",title:"Machine_Learning"},"/Machine_Learning/Structure/Regression":{content:"# Mathematical\n![[Pasted image 20211006161933.png]]\n- N: the number of samples\n- i: index  \n- x: predictor\n- y: (continuous) true label\n- dataset:  {(xi,yi) ∶ 1 ≤ i ≤ N}, (xi,yi) is sample i\n- f(⋅): model\n- yˆi = f(xi): predicted label\n- ei = yi − yˆi: prediction error\n\n# 1. [[content/Machine_Learning/Regression_Quality_Metric]]\n# 2. Model\n \u003e generate multiple shapes by tuning  parameters.\n- ![[Pasted image 20211006194951.png]]		\n- Priors: Type of model (linear, polynomial, etc).\n- Data: Labelled samples, predictors and true (continuous) label. \n- Model: Predicts a label based on the predictors.\n\n## Type\n[[content/Machine_Learning/Linear_Regression]]\n[[content/Machine_Learning/Logistic_Model#^bbc977|Logistic regression]]",title:"Regression"},"/Machine_Learning/Structure/Supervised_Learning":{content:"\u003e estimate/ predict the missing value/ label/ attribute\n- [[content/Machine_Learning/Structure/Classification]]: T/F\n- [[content/Machine_Learning/Structure/Regression]]: y = 2x+3",title:"Supervised_Learning"},"/Machine_Learning/Structure/Unsupervised_Learning":{content:"find the underlying structure to identify anomalies/ outlier \n	- Structure Analysis: \n		- Cluster analysis: groups of data points\n		- Component analysis: directions of interest\n	- Density Estimation: describe the distribution of samples in the attribute space",title:"Unsupervised_Learning"},"/Machine_Learning/Testing":{content:"## Performance \n- best model: with the highest deployment performance\n- evaluate the performance\n	- quality metric: to quantify  ^f67765\n	- data: to assess\n- designed before build\n	- avoid data-traps (like confirmation bias)\n- focus on test task \u003e\u003e\u003e spilt the data\n\n### Assessing\n- test dataset: [[Sampling#^41ffae|a subset of data]], randomly extracted\n- test deployment performance: **estimation** of the true performance\n- comparing:\n	\u003e The Infinite Monkey Theorem\n	- lower MSE != better performance [[#^ccf020|random]] can't express",title:"Testing"},"/Machine_Learning/The_Bayes_Classifier":{content:"# The Bayes Classifier ^95fc31\n- a classifier uses the True [[#^68e85f|Posterior Probabilities]]\n- use odds ratio([[#^68e85f|Posterior Probabilities]] or [[#^555d72|Class Priors]]+[[#^3a3076|Class Densities]]) to achieves ***the highest accuracy*** by comparing: $\\frac {P(y=red|x)}{P(y=blue|x)} = \\frac {P(x|y=red)P(y=red)}{P(x|y=blue)P(y=blue)}$ ^839888\n	- if \u003e1 ==\u003e y = red\n	- if \u003c 1 ==\u003e y = blue\n- a ideal classifier: we never know $\\frac {P(y=red|x)}{P(y=blue|x)}$\n\n\n***\n\u003e ![[Screenshot 2021-11-06 at 10.25.09.png]]\n\n## Class Priors ^555d72\n\u003e - assume 70 % of the population y=red, 30% y=blue.\n-  P(y=red) = 0.7, P(y=blue) = 0.3.\n\n### Estimate\n- use a dataset: $P(y=red) = \\frac {N(red\\ samples)}{N(samples)}$\n***\n## Class Densities ^3a3076\n\u003e- assume $\\frac{1}{4}x = a, \\frac{3}{4}x = b$ in the red example,  $\\frac{2}{3}x = a, \\frac{1}{3}x = b$ in the blue example\n- $P(x=a|y=red) = \\frac {1}{4}$\n- $P(x=b|y=red) = \\frac {3}{4}$\n- $P(x=a|y=blue) = \\frac {2}{3}$\n- $P(x=b|y=blue) = \\frac {1}{3}$\n### Estimate\n1. build class densities: [[content/Machine_Learning/Structure/Unsupervised_Learning]]\n2.  ## Gaussian Density\n	### Discriminant Analysis\n- we assume the class densities are Gaussian.\n- one predictor:![[Screenshot 2021-11-06 at 11.45.17.png]]\n	- parameters:  $µo$ is the mean and $σ^2o$\nis variance of the Gaussian density.\n![[Screenshot 2021-11-06 at 12.20.44.png]]\n- K predictors:![[Screenshot 2021-11-06 at 11.46.48.png]]\n	- parameters:  $µo$ is the mean and $Σo$ is  covariance matrix.\n![[Screenshot 2021-11-06 at 12.23.47.png]]\n- linear discriminant analysis (LDA)\n	- If $Σblue= Σred$ ==\u003e the boundary is linear. We call this scenario. \n	- ratio	 of the cost:![[Screenshot 2021-11-06 at 12.29.31.png]] ^4f4693\n- quadratic discriminant analysis (QDA)\n	- the boundary is quadratic\n\n***\n## Posterior Probabilities ^68e85f\n- **Accuracy **\n- $P(y=red|x)$\n- $P(y=blue|x)$\n\u003e -* fallacy of the transposed conditional*: a confusion between [[#^3a3076|Class Densities]] and [[#^68e85f|Posterior Probabilities]]\n\n### Bayes Rule\n- $P(y=red|x) = \\frac {P(x|y=red)P(y=red)}{p(x)}$ \n- $P(y=blue|x) = \\frac {P(x|y=blue)P(y=blue)}{p(x)}$ \n\n\n# A Bayesian Extension ^a80775\n[[content/Machine_Learning/Classification_Quality_Metric]]\n\n\n### Minimize the Cost\n- ![[Screenshot 2021-11-06 at 14.54.56.png]]\n- $T = \\frac {C(blue)}{C(red)} = ratio\\ of\\ the\\ cost = a\\ threshold\\ value = boundary$ [[#^4f4693]]\n\n### Example\n- 2 classes: blue and red.\n	- $P(y=blue|x) = 0.1; P(y=red|x) = 0.9$\n-  the cost of misclassifying a  sample:\n	-  $C(blue)=\\$5000; C(red)=\\$20$\n- The Bayesian Classifier would label $x$ as red, because of the expected cost:\n	- $C(blue)*P(y=blue|x) = \\$500$\n	- $C(red)*P(y=red|x) = \\$18$",title:"The_Bayes_Classifier"},"/Machine_Learning/Training":{content:"## What we have\n1. a family of candidate models: e.g. linear models\n2. [[content/Machine_Learning/Regression_Quality_Metric]]: e.g. the error\n3. training data:\n	- ![[Screenshot 2021-11-15 at 10.04.34.png]]\n- therefore, we can get only empirical error surface  ^10ee42\n	- ![[Screenshot 2021-11-14 at 15.23.55.png]]\n- instead of true error surface.\n	- ![[Screenshot 2021-11-14 at 15.23.01.png]]\n\n[[content/Machine_Learning/Optimisation#^607e71]]\n\n## What can we do",title:"Training"},"/Machine_Learning/Transform":{content:"---\n\n\u003e change the way represent samples\n- one of the most important: \nmany ML models = a transformation + a simple model\n\u003e - extract features from each pic as training data. \n\u003e - ![[Screenshot 2021-11-02 at 19.30.59.png]]\n\u003e -  if we extract 4 values, we need fewer training pics.",title:"Transform"},"/Machine_Learning/Validation":{content:"\u003e models work together --\u003e select the best family\n\n- a family of models with random subsets of the data (learn different things)\n- different models with random subsets of attributes (like [[#^648b6a|wrapping]])\n- different family of models altogether\n***\n## Validation set approach\n- ![[Screenshot 2021-11-16 at 10.09.01.png]]\n	- result: error\n\n## LOOCV: Leave-one-out cross-validation\n- ![[Screenshot 2021-11-16 at 10.10.35.png]]\n	- result: error.avg()\n\n## k-fold cross-validation\n\u003e LOOCV is a special case of k-fold cross-validation, where k = N .\n- ![[Screenshot 2021-11-16 at 10.12.08.png]]\n	- result: error.avg()\n\n***\n## Bagging\n- generate K sub-datasets by bootstrap\n- train K simple base models with each sub-datasets\n- combines the predictions of the base models by averaging or voting\n	- an vote example: $f(x)=\\sum fk(x)/K$ ![[Screenshot 2021-11-02 at 22.13.46.png]]\n	``` mermaid\n	flowchart LR\n	A(data) --\u003e B(extract dark data) --\u003e C(fit a linear model) --\u003e D(combine to a non-linear model)\n	C --\u003e|repeat| A\n	```\n***\n## Random forests\n- train many individual trees\n- randomising the training samples and the predictors\n- predictors: average the individual prediction\n- +: great accuracy (than a single tree)\n- -: expensive to train, harder to interpret (than a single tree)\n### Tree\n- to create pure leaves, otherwise the algorithm will confused: [[#^0ccc67|The XOR problem]]\n	- leaf: one of the decision regions; result\n	```mermaid\n	graph TD\n	A[Root: salary \u003e S] --\u003eB(Leaf: Bad)\n	A --\u003e C(Age \u003e 40)\n	C --\u003e D(Leaf: neutral)\n	C --\u003e E(Leaf: good)\n	```\n- splits are axis-parallel\n	- otherwise use [[content/Machine_Learning/Linear_Classifier]]\n### The XOR problem ^0ccc67\n- ![[Screenshot 2021-11-02 at 22.25.45.png]]\n\n***\n## Boosting\n- sequence: supply previous sample\n- ![[Screenshot 2021-11-17 at 09.42.26.png]]![[Screenshot 2021-11-17 at 09.42.41.png]]\n-",title:"Validation"},"/templates/post":{content:"",title:"{{title}}"}};for(const[b,a]of Object.entries(scrapedContent))contentIndex.add({id:b,title:a.title,content:removeMarkdown(a.content)});const highlight=(i,j)=>{const a=20,k=j.split(/\s+/).filter(a=>a!==""),b=i.split(/\s+/).filter(a=>a!==""),f=a=>k.some(b=>a.toLowerCase().startsWith(b.toLowerCase())),d=b.map(f);let e=0,g=0;for(let b=0;b<Math.max(d.length-a,0);b++){const f=d.slice(b,b+a),c=f.reduce((a,b)=>a+b,0);c>=e&&(e=c,g=b)}const c=Math.max(g-a,0),h=Math.min(c+2*a,b.length),l=b.slice(c,h).map(a=>{return f(a)?`<span class="search-highlight">${a}</span>`:a}).join(" ").replaceAll('</span> <span class="search-highlight">'," ");return`${c===0?"":"..."}${l}${h===b.length?"":"..."}`},resultToHTML=({url:b,title:c,content:d,term:a})=>{const e=removeMarkdown(d),f=highlight(c,a),g=highlight(e,a);return`<button class="result-card" id="${b}">
        <h3>${f}</h3>
        <p>${g}</p>
    </button>`},redir=(a,b)=>{window.location.href="https://jiahaom.github.io/ds/"+`${a}#:~:text=${encodeURIComponent(b)}`},fetch=a=>({id:a,url:a,title:scrapedContent[a].title,content:scrapedContent[a].content}),source=document.getElementById('search-bar'),results=document.getElementById("results-container");let term;source.addEventListener("keyup",a=>{if(a.key==="Enter"){const a=document.getElementsByClassName("result-card")[0];redir(a.id,term)}}),source.addEventListener('input',a=>{term=a.target.value,contentIndex.search(term,[{field:"content",limit:10,suggest:!0},{field:"title",limit:5}]).then(c=>{const a=b=>{const a=c.filter(a=>a.field===b);return a.length===0?[]:[...a[0].result]},d=[...a('title'),...a('content')],b=d.map(fetch);if(b.length===0)results.innerHTML=`<div class="result-card">
                    <p>No results.</p>
                </div>`;else{results.innerHTML=b.map(a=>resultToHTML({...a,term})).join("\n");const a=document.getElementsByClassName("result-card");[...a].forEach(a=>{a.onclick=()=>redir(a.id,term)})}})});const searchContainer=document.getElementById("search-container");function openSearch(){searchContainer.style.display==="none"||searchContainer.style.display===""?(source.value="",results.innerHTML="",searchContainer.style.display="block",source.focus()):searchContainer.style.display="none"}function closeSearch(){searchContainer.style.display="none"}document.addEventListener('keydown',a=>{a.key==="/"&&(a.preventDefault(),openSearch()),a.key==="Escape"&&(a.preventDefault(),closeSearch())}),window.addEventListener('DOMContentLoaded',()=>{const a=document.getElementById("search-icon");a.addEventListener('click',a=>{openSearch()}),a.addEventListener('keydown',a=>{openSearch()}),searchContainer.addEventListener('click',a=>{closeSearch()}),document.getElementById("search-space").addEventListener('click',a=>{a.stopPropagation()})})</script><div class=singlePage><header><h1>Optimisation</h1><svg tabindex="0" id="search-icon" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg><div class=spacer></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><aside class=mainTOC><h3>Table of Contents</h3><nav id=TableOfContents><ol><li><a href=#gradient-descent-e433dc>Gradient Descent ^e433dc</a><ol><li><a href=#contentmachine_learningregression_quality_metricd91d7emmse-the-bestlowest-mse-for-training-data-bab8a8>[[content/Machine_Learning/Regression_Quality_Metric#^d91d7e|MMSE: the best/lowest MSE for training data]] ^bab8a8</a></li><li><a href=#contentmachine_learningtraining10ee42training>[[content/Machine_Learning/Training#^10ee42|Training]]</a></li><li><a href=#optimisation>Optimisation</a></li></ol></li></ol></nav></aside><blockquote><p>find the best model if we have:</p><ul><li>a collection of candidate models</li><li>quality metric</li><li>ideal description of the target population</li></ul></blockquote><h2 id=gradient-descent-e433dc>Gradient Descent ^e433dc</h2><ul><li>update iteratively / parameter tuning</li><li>$w_{new} = w_{old}-\epsilon ∇E(w_{old})$<ul><li>$w: model$</li><li>$\epsilon: learning\ rate/step\ size$</li><li>$∇E(w_{old}): slope$<ul><li>large: overshoot</li><li>small: slow</li></ul></li></ul></li><li>initial model $w$ is crucial<ul><li>usually chosen randomly</li></ul></li><li>stopping strategy<ul><li>Gradient Descent will not reach the optimal model<ul><li>Number of iterations.</li><li>Processing time.</li><li>Error value.</li><li>Relative change of the error value.</li></ul></li></ul></li></ul><h3 id=contentmachine_learningregression_quality_metricd91d7emmse-the-bestlowest-mse-for-training-data-bab8a8>[[content/Machine_Learning/Regression_Quality_Metric#^d91d7e|MMSE: the best/lowest MSE for training data]] ^bab8a8</h3><ul><li>[[content/Machine_Learning/Linear_Regression#^b14eb7|Linear Model]]:<ul><li>$\hat y = Xw$</li></ul></li><li>[[content/Machine_Learning/Regression_Quality_Metric#^a03fa6|E_MSE]]:
- $E_{MSE}(w) = \frac{1}{N}(y-\hat y)^T(y-\hat y)$
= $E_{MSE}(w) =\frac{1}{N}(y-Xw)^T(y-Xw)$<ul><li>the resulting gradient of the MSE is:<ul><li>$assume:\bigtriangledown E_{MSE}(w) = \frac{-2}{N}X^T(y-Xw) = 0$<ul><li>$w =(X^TX)^{-1}X^Ty$</li></ul></li></ul></li></ul></li></ul><h3 id=contentmachine_learningtraining10ee42training>[[content/Machine_Learning/Training#^10ee42|Training]]</h3><ul><li>![[Screenshot 2021-11-16 at 09.36.33.png]]</li></ul><h4 id=data-size>Data Size</h4><ul><li>Batch gradient descent: whole training dataset.</li><li>Stochastic gradient descent: randomly, one sample.</li><li>Mini-batch gradient descent: a small subset from the training dataset.</li></ul><h3 id=optimisation>Optimisation</h3><ul><li>Momentum</li><li>RMSProp</li><li>Adam</li></ul></article><hr><div class=page-end><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script src=https://cdn.jsdelivr.net/npm/d3@6></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script>const index={backlinks:{"/Classification_Quality_Metric":[{source:"/Machine_Learning/Classification",target:"/Classification_Quality_Metric",text:"Classification_Quality_Metric"}],"/Linear_Classifier":[{source:"/Machine_Learning/Classification",target:"/Linear_Classifier",text:"Linear_Classifier"}],"/Logistic_Model":[{source:"/Machine_Learning/Classification",target:"/Logistic_Model",text:"Logistic Classifier"}],"/Machine_Learning/Structure/Classification":[{source:"/",target:"/Machine_Learning/Structure/Classification",text:"Classification"}],"/Machine_Learning/Structure/Machine_Learning":[{source:"/",target:"/Machine_Learning/Structure/Machine_Learning",text:"Machine_Learning"}],"/Machine_Learning/Structure/Regression":[{source:"/",target:"/Machine_Learning/Structure/Regression",text:"Regression"}],"/Machine_Learning/Structure/Supervised_Learning":[{source:"/",target:"/Machine_Learning/Structure/Supervised_Learning",text:"Supervised_Learning"}],"/Machine_Learning/Structure/Unsupervised_Learning":[{source:"/",target:"/Machine_Learning/Structure/Unsupervised_Learning",text:"Unsupervised_Learning"}],"/The_Bayes_Classifier":[{source:"/Machine_Learning/Classification",target:"/The_Bayes_Classifier",text:"Posterior Probabilities"}]},links:{"/":[{source:"/",target:"/Machine_Learning/Structure/Machine_Learning",text:"Machine_Learning"},{source:"/",target:"/Machine_Learning/Structure/Supervised_Learning",text:"Supervised_Learning"},{source:"/",target:"/Machine_Learning/Structure/Classification",text:"Classification"},{source:"/",target:"/Machine_Learning/Structure/Regression",text:"Regression"},{source:"/",target:"/Machine_Learning/Structure/Unsupervised_Learning",text:"Unsupervised_Learning"}],"/Machine_Learning/Classification":[{source:"/Machine_Learning/Classification",target:"/Classification_Quality_Metric",text:"Classification_Quality_Metric"},{source:"/Machine_Learning/Classification",target:"/Linear_Classifier",text:"Linear_Classifier"},{source:"/Machine_Learning/Classification",target:"/Logistic_Model",text:"Logistic Classifier"},{source:"/Machine_Learning/Classification",target:"/The_Bayes_Classifier",text:"Posterior Probabilities"}]}},links=[{source:"/Machine_Learning/Classification",target:"/Classification_Quality_Metric",text:"Classification_Quality_Metric"},{source:"/Machine_Learning/Classification",target:"/Linear_Classifier",text:"Linear_Classifier"},{source:"/Machine_Learning/Classification",target:"/Logistic_Model",text:"Logistic Classifier"},{source:"/Machine_Learning/Classification",target:"/The_Bayes_Classifier",text:"Posterior Probabilities"},{source:"/",target:"/Machine_Learning/Structure/Machine_Learning",text:"Machine_Learning"},{source:"/",target:"/Machine_Learning/Structure/Supervised_Learning",text:"Supervised_Learning"},{source:"/",target:"/Machine_Learning/Structure/Classification",text:"Classification"},{source:"/",target:"/Machine_Learning/Structure/Regression",text:"Regression"},{source:"/",target:"/Machine_Learning/Structure/Unsupervised_Learning",text:"Unsupervised_Learning"}],curPage="/ds/Machine_Learning/Optimisation",pathColors=[{"/moc":"#4388cc"}],parseIdsFromLinks=a=>[...new Set(a.flatMap(a=>[a.source,a.target]))],data={nodes:parseIdsFromLinks(links).map(a=>({id:a})),links},color=a=>{if(a.id===curPage||a.id==="/"&&curPage==="")return"var(--g-node-active)";for(const b of pathColors){const c=Object.keys(b)[0],d=b[c];if(a.id.startsWith(c))return d}return"var(--g-node)"},drag=c=>{function d(b,a){b.active||c.alphaTarget(1).restart(),a.fx=a.x,a.fy=a.y}function e(a,b){b.fx=a.x,b.fy=a.y}function f(b,a){b.active||c.alphaTarget(0),a.fx=null,a.fy=null}const a=!0,b=()=>{};return d3.drag().on("start",a?d:b).on("drag",a?e:b).on("end",a?f:b)},height=250,width=document.getElementById("graph-container").offsetWidth,simulation=d3.forceSimulation(data.nodes).force("charge",d3.forceManyBody().strength(-20)).force("link",d3.forceLink(data.links).id(a=>a.id)).force("center",d3.forceCenter()),svg=d3.select('#graph-container').append('svg').attr('width',width).attr('height',height).attr("viewBox",[-width/2,-height/2,width,height]),enableLegend=!1;if(enableLegend){const a=[{Current:"var(--g-node-active)"},{Note:"var(--g-node)"},...pathColors];a.forEach((a,b)=>{const c=Object.keys(a)[0],d=a[c];svg.append("circle").attr("cx",-width/2+20).attr("cy",height/2-30*(b+1)).attr("r",6).style("fill",d),svg.append("text").attr("x",-width/2+40).attr("y",height/2-30*(b+1)).text(c).style("font-size","15px").attr("alignment-baseline","middle")})}const link=svg.append("g").selectAll("line").data(data.links).join("line").attr("class","link").attr("stroke","var(--g-link)").attr("stroke-width",2).attr("data-source",a=>a.source.id).attr("data-target",a=>a.target.id),graphNode=svg.append("g").selectAll("g").data(data.nodes).enter().append("g"),node=graphNode.append("circle").attr("class","node").attr("id",a=>a.id).attr("r",a=>{const b=index.links[a.id]?.length||0,c=index.backlinks[a.id]?.length||0;return 3+(b+c)/4}).attr("fill",color).style("cursor","pointer").on("click",(b,a)=>{window.location.href="https://jiahaom.github.io/ds/"+a.id.replace(" ","-").replace("%20","-")}).on("mouseover",function(f,a){d3.selectAll(".node").transition().duration(100).attr("fill","var(--g-node-inactive)");const c=parseIdsFromLinks([...index.links[a.id]||[],...index.backlinks[a.id]||[]]),d=d3.selectAll(".node").filter(a=>c.includes(a.id)),b=a.id,e=d3.selectAll(".link").filter(a=>a.source.id===b||a.target.id===b);d.transition().duration(200).attr("fill",color),e.transition().duration(200).attr("stroke","var(--g-link-active)"),d3.select(this.parentNode).select("text").raise().transition().duration(200).style("opacity",1)}).on("mouseleave",function(d,b){d3.selectAll(".node").transition().duration(200).attr("fill",color);const a=b.id,c=d3.selectAll(".link").filter(b=>b.source.id===a||b.target.id===a);c.transition().duration(200).attr("stroke","var(--g-link)"),d3.select(this.parentNode).select("text").transition().duration(200).style("opacity",0)}).call(drag(simulation)),labels=graphNode.append("text").attr("dx",12).attr("dy",".35em").text(a=>a.id.replace("%20","-")).style("opacity",0).style("pointer-events","none").call(drag(simulation)),enableZoom=!0;enableZoom&&svg.call(d3.zoom().extent([[0,0],[width,height]]).scaleExtent([.25,4]).on("zoom",({transform:a})=>{link.attr("transform",a),node.attr("transform",a),labels.attr("transform",a)})),simulation.on("tick",()=>{link.attr("x1",a=>a.source.x).attr("y1",a=>a.source.y).attr("x2",a=>a.target.x).attr("y2",a=>a.target.y),node.attr("cx",a=>a.x).attr("cy",a=>a.y),labels.attr("x",a=>a.x).attr("y",a=>a.y)})</script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2021</p><a href=../../>Home</a>
<a href=https://twitter.com/_jzhao>Twitter</a><a href=https://github.com/jackyzha0>Github</a></footer></div></div></body></html>